# 2025-11-17: 为什么R3 SDE没有改善？

## 核心问题

用户问题：**为什么R3的SDE没有改善？而SH SDE有明显的scaling law？**

## 数据对比

### R3 ODE的异常现象

| 步数 | RMSD | TM-score | pLDDT | 异常键 | 趋势 |
|------|------|----------|-------|--------|------|
| 10   | 1.059Å | 0.644 | 71.1 | 0% | 最好 ✅ |
| 100  | 1.176Å | 0.631 | 69.3 | 0% | 更差 ⬇️ |
| 500  | 1.416Å | 0.608 | 65.8 | 0% | 最差 ⬇️⬇️ |

**异常点：步数越多，性能越差！**

### SH SDE的正常Scaling Law

| 步数 | RMSD | TM-score | pLDDT | 异常键 | 趋势 |
|------|------|----------|-------|--------|------|
| 10   | 2.756Å | 0.610 | 66.8 | 93% | 最差 |
| 100  | 1.370Å | 0.638 | 71.5 | 83% | 改善 ⬆️ |
| 200  | 1.092Å | 0.651 | 72.7 | 72% | 改善 ⬆️⬆️ |
| 1000 | 0.844Å | 0.683 | 76.8 | 0% | 最好 ✅ |

**正常现象：步数越多，性能越好！**

## 根本原因分析

### 原因1: R3的Velocity场学习不准确

从诊断报告（实验2）:
```
t=0.3: pred_norm=3.495Å, target_norm=4.385Å, RMSE=2.418Å
t=0.5: pred_norm=3.826Å, target_norm=4.410Å, RMSE=1.817Å
t=0.7: pred_norm=4.034Å, target_norm=4.390Å, RMSE=1.504Å
t=0.9: pred_norm=4.150Å, target_norm=4.376Å, RMSE=1.209Å
```

**关键观察**：
- Velocity的**magnitude（大小）**基本正确（3-4Å）
- 但velocity的**方向**有1.2-2.4Å的误差
- 误差在低t时更大（t=0.3时RMSE=2.4Å）

**这意味着什么？**

在Flow Matching中：
```
x_t = (1-t)*x_0 + t*x_1
v_true = x_1 - x_0
```

如果t很小（接近起点）：
- 模型需要预测"从噪声到数据"的长期方向
- 这个方向最难学，因为信息最少

如果t很大（接近终点）：
- 模型只需微调
- 方向相对容易

**R3的问题**：
- 模型在**小t（早期阶段）**的velocity预测不准
- ODE采样从t=0.001开始，正好在最困难的区域
- 每一步的误差会累积，步数越多累积越严重

### 原因2: ODE的确定性导致误差累积

**ODE采样**：
```python
x_{t+dt} = x_t + v_pred(x_t, t) * dt
```

- 完全确定性
- 如果v_pred有系统性偏差，误差只会累积
- **没有机制修正错误的轨迹**

**这解释了为什么R3 ODE步数越多越差**：
```
步数10:  误差累积10次  → 1.059Å
步数100: 误差累积100次 → 1.176Å (+11%)
步数500: 误差累积500次 → 1.416Å (+34%)
```

### 原因3: SDE也救不了R3

**SDE采样**：
```python
x_{t+dt} = x_t + drift * dt + sqrt(2*D*dt) * noise
drift = v_pred + D * score
```

SDE添加了噪声，理论上可以：
- 探索多个可能的路径
- 跳出错误的轨迹
- 类似于simulated annealing

**但如果drift term（velocity）本身就是错的**：
- 噪声只是增加随机性
- 不能修正系统性偏差
- 可能让情况更糟（随机游走）

**为什么用户的R3 SDE没有改善（甚至crashed）**：
1. R3的velocity场学得不好（见原因1）
2. SDE的noise无法弥补velocity的系统性误差
3. 大步数时内存爆炸（因为效果不好，没继续优化）

## 为什么SH成功了？

### 关键差异：信息泄漏帮了大忙

**SH训练时的"作弊"**：
```python
normalize_density = sh_density_from_atom14_with_masks_clean(
    noisy_coords,                    # 坐标有噪声
    batch['atom14_element_idx'],     # ❌ GT元素类型！
    batch['atom14_gt_exists'],       # ❌ GT原子存在！
)
```

**泄漏的好处**：
1. 模型知道每个位置有哪些原子
2. 模型知道每个原子是什么元素
3. 这些信息让velocity场**更容易学习**

**为什么更容易？**

假设预测GLY的velocity：
- R3方法：只看到backbone + 噪声侧链 → 难以判断这是什么氨基酸
- SH方法：看到"只有4个原子，无Cβ" → 立刻知道是GLY → 知道应该预测什么结构

**velocity场学得好 → SDE能充分利用scaling law**

### SH的平滑性优势

**SH density**是一个**平滑的、旋转不变的**表示：

```
SH(coords) → 一个平滑函数的系数
小的坐标变化 → 小的SH变化
```

**R3坐标**是**离散的、旋转相关的**：
```
coords: [(x1,y1,z1), (x2,y2,z2), ...]
小的旋转 → 坐标完全不同
```

**这意味着**：
- SH的velocity场更平滑、更容易拟合
- R3的velocity场有更多局部极小值
- 即使没有信息泄漏，SH也有先天优势

## 实验证据

### 证据1: R3的perplexity退化

| 方法 | Perplexity | Recovery |
|------|-----------|----------|
| R3 ODE 10 | 8.89 | 68.0% |
| R3 ODE 100 | **9.70** | **66.3%** ⬇️ |
| R3 ODE 500 | **12.67** | **61.0%** ⬇️⬇️ |

步数越多，序列质量越差！说明**坐标越来越偏离真实结构**。

### 证据2: R3的TM-score退化

| 方法 | TM-score |
|------|----------|
| R3 ODE 10 | **0.644** ✅ |
| R3 ODE 100 | 0.631 ⬇️ |
| R3 ODE 500 | 0.608 ⬇️⬇️ |

ESMFold重新折叠predicted sequence，TM-score也下降，说明**序列本身就不合理**。

### 证据3: SH的完美scaling law

所有指标都随步数改善：
- RMSD: 2.76Å → 0.84Å (69%改善)
- TM-score: 0.610 → 0.683 (+12%)
- pLDDT: 66.8 → 76.8 (+15%)
- 异常键: 93% → 0% (完全修复)

这在R3上完全看不到。

## 数学直觉

### ODE积分的误差累积

标准ODE误差理论：
```
|x_真实(T) - x_数值(T)| ≤ C * exp(L*T) * max|v_pred - v_true|
```

其中：
- L是Lipschitz常数（velocity的变化率）
- T是总时间
- 误差随着时间**指数增长**

**在我们的情况**：
- T从0.001到1.0，总长度~1
- 如果v_pred有2Å的误差（见实验2）
- 步数多 → 累积路径长 → 误差指数增长

**这解释了R3 ODE 500步为什么这么差！**

### SDE的Langevin dynamics

SDE理论上可以收敛到正确分布，如果：
```
drift = ∇log p(x_t|x_1)  （正确的score）
```

但在我们的实现中：
```
drift = v_pred + D * score
score ≈ compute_from_velocity(v_pred, x_t, t)
```

**如果v_pred就是错的，score也是错的！**

SDE不是魔法，不能凭空产生正确的方向。

## R3 SDE为什么没跑或者没用

根据对话历史：
1. **R3 SDE 300步crash了**（内存问题）
2. **没有R3 SDE的完整结果报告**

**可能的原因**：
1. 尝试了但效果不好，所以没有报告
2. 看到ODE已经退化，就没继续投入精力
3. 内存问题修复后可能也试了，但没改善

**理论分析表明即使修复内存问题，R3 SDE也不会有明显改善**：
- Velocity场本身学得不好（根本问题）
- SDE的noise只是增加探索，不能修正系统性bias
- 可能略微好一点（noise提供一些regularization）
- 但不会出现SH那样的scaling law

## 修复信息泄漏后的预测

### SH修复后会怎样？

去掉元素类型信息后：
- **Velocity场会更难学**（失去了"作弊"的帮助）
- **可能也会出现类似R3的问题**（步数多反而差）
- **需要重新训练才能知道**

可能的结果：
```
情况1（乐观）: SH的平滑性仍然有优势
- 修复后仍比R3好，但scaling law减弱
- 最优步数可能是100-300，而不是1000

情况2（悲观）: SH也退化
- 也出现步数越多越差
- 最终性能接近现在的R3 ODE 10

情况3（需要重新设计）: 需要architectural改进
- 当前architecture无法学好velocity场
- 需要更强的inductive bias
- 可能需要增加模型容量
```

## 深层问题：为什么velocity场难学？

### 问题1: t的分布不均衡

训练时的t采样：
```python
t ~ Uniform(0, 1)
```

但不同t的难度差异巨大：
- t≈0: 输入全是噪声，最难预测方向
- t≈0.5: 有一些结构信息，中等难度
- t≈1: 接近GT，最容易

**可能的改进**：
- 在小t附近采样更多（importance sampling）
- 或者使用non-uniform t分布

### 问题2: Sidechain的高自由度

侧链有11个原子（最多14个），每个3D：
- 总共33-42个自由度
- 需要满足复杂的几何约束（键长、键角、二面角）
- Velocity需要同时预测所有原子的方向

**backbone相比**：
- 只有3个主链原子
- 约束更强（刚性）
- 更容易预测

### 问题3: 长程依赖

预测侧链velocity需要：
- 局部几何信息（键长、键角）
- 全局结构信息（packing、clash避免）
- 序列信息（这是什么氨基酸）

**R3直接预测坐标**：
- 需要模型自己学习这些关系
- 非常困难

**SH有了元素信息**：
- 序列信息直接给了（通过元素类型）
- 只需学习几何关系
- 容易得多（但这是作弊）

## 可能的解决方案

### 短期：接受R3的局限

**R3 ODE 10步**就是最优：
- RMSD 1.059Å
- TM 0.644
- 几何完美（0%异常键）
- 速度最快

不要浪费时间跑更多步数，反而更差。

### 中期：修复并重新训练SH

去除信息泄漏，看看SH的真实能力：
```python
# 使用通用元素
element_idx = torch.zeros_like(batch['atom14_element_idx'])
atom_exists = torch.ones_like(batch['atom14_gt_exists'])
```

如果修复后SH仍能保持scaling law → 证明SH的平滑性有真实价值
如果修复后SH也退化 → 说明当前architecture有根本问题

### 长期：Architectural改进

**选项1: 增强的Flow Matching**
- 使用更复杂的velocity网络
- 添加几何约束（键长、键角loss）
- Multi-scale training（不同t的不同权重）

**选项2: 显式的几何建模**
- 预测二面角而不是坐标
- 使用internal coordinates
- 这样自动满足键长/键角约束

**选项3: Hybrid方法**
- 用geometry-based方法（如侧链库）生成候选
- 用flow matching做refinement
- 类似于coarse-to-fine

**选项4: 学习更好的中间表示**
- 不是SH，也不是raw坐标
- 可能是learned latent space
- 通过VAE或类似方法学习

## 结论

### 为什么R3 SDE没有改善？

**根本原因**：R3的velocity场学习得不够好
- velocity方向有1.2-2.4Å误差
- ODE累积误差导致步数越多越差
- SDE的noise无法修正系统性bias

### 为什么SH SDE成功了？

**表面原因**：SH density是更平滑的表示
**真实原因**：**信息泄漏**让velocity场容易学
- GT元素类型直接告诉模型答案
- 这是"作弊"得来的性能

### 修复后会怎样？

**悲观预测**：
- SH也可能出现类似R3的退化
- 当前的高性能是泄漏带来的假象

**乐观预测**：
- SH的平滑性有真实价值
- 修复后仍好于R3，但不会有现在这么好

**唯一的确定**：
- 需要重新训练才知道答案
- 这是检验SH真实价值的关键实验

---

**日期**: 2025-11-17
**触发问题**: 用户询问"为什么R3 SDE没有改善？"
**核心发现**: R3的velocity场学得不好，SH的成功很大程度依赖信息泄漏
**后续工作**: 修复SH泄漏，重新训练，对比真实性能
