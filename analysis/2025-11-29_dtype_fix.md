# Dtype Float64/Float32 修复报告

**日期**: 2025-11-29
**问题**: RuntimeError: Found dtype Double but expected Float
**原因**: Python浮点字面量默认是float64，与PyTorch的float32张量混合运算导致dtype提升

---

## 问题根源

PyTorch训练中所有张量应该是 `torch.float32`，但Python的浮点字面量（如 `0.5`, `2.0`）默认是 `float64`。当它们与 `float32` 张量运算时，结果会被提升到 `float64`，导致反向传播时出现dtype不匹配错误。

### 典型错误示例

```python
# ❌ 错误写法
tensor = torch.randn(3, 3, dtype=torch.float32)
result = 0.5 * tensor  # 0.5是float64，result变成float64！

# ✅ 正确写法1: 用tensor的inplace方法
result = tensor.mul_(0.5)  # 保持float32

# ✅ 正确写法2: 先乘后用字面量
result = (tensor + tensor).mul_(0.5)

# ✅ 正确写法3: 显式转换
result = tensor * torch.tensor(0.5, dtype=tensor.dtype)
```

---

## 修复位置

### 1. **data/GaussianRigid.py:69** ✅

**原代码**:
```python
Sigma = 0.5 * (Sigma + Sigma.transpose(-1, -2))
```

**修复后**:
```python
Sigma = (Sigma + Sigma.transpose(-1, -2)).mul_(0.5)  # inplace保持dtype
```

**原因**:
- `0.5` 是 float64
- 与 float32 的 `Sigma` 相乘导致结果变成 float64
- 后续 Cholesky 分解期望 float32，导致错误

### 2. **models/loss.py:555-560** ✅

**原代码**:
```python
mahal_sq = -2.0 * fused_gaussian_overlap_score(delta, sigma_exp)
L_chol = torch.linalg.cholesky(sigma_pred)
log_det = 2.0 * torch.diagonal(L_chol, dim1=-2, dim2=-1).log().sum(-1)
nll_per_atom = 0.5 * (mahal_sq + log_det.unsqueeze(-1))
```

**修复后**:
```python
mahal_sq = fused_gaussian_overlap_score(delta, sigma_exp).mul_(-2.0)
L_chol = torch.linalg.cholesky(sigma_pred)
log_det = torch.diagonal(L_chol, dim1=-2, dim2=-1).log().sum(-1).mul_(2.0)
nll_per_atom = (mahal_sq + log_det.unsqueeze(-1)).mul_(0.5)
```

**原因**:
- `-2.0`, `2.0`, `0.5` 都是 float64
- 每次运算都可能提升 dtype
- 使用 `.mul_()` 保持原始 dtype

### 3. **models/flow_model.py:448,453** ✅

**原代码**:
```python
safe_count = torch.clamp(atom_count, min=1.0)
local_mean[is_gly] = 0.0
```

**修复后**:
```python
safe_count = atom_count.clamp(min=1.0)
local_mean[is_gly] = torch.zeros_like(local_mean[is_gly])
```

**原因**:
- `torch.clamp(x, min=1.0)` 中的 `1.0` 是 float64
- 使用 `x.clamp(min=1.0)` 保持原始 dtype
- 直接赋值 `0.0` 也可能导致 dtype 提升，改用 `torch.zeros_like()`

---

## 验证测试

创建了 `test_dtype_fix.py` 验证修复：

```bash
$ python test_dtype_fix.py
Using device: cuda

创建OffsetGaussianRigid...
  trans.dtype: torch.float32
  scaling_log.dtype: torch.float32
  local_mean.dtype: torch.float32

计算协方差矩阵...
  ✓ 协方差矩阵计算成功
  cov.dtype: torch.float32
  cov.shape: torch.Size([2, 5, 3, 3])
  ✓ 正确！dtype是float32

测试Cholesky分解...
  ✓ Cholesky分解成功
  L.dtype: torch.float32

测试log_det计算...
  ✓ log_det计算成功
  log_det.dtype: torch.float32

============================================================
✓✓✓ 所有dtype检查通过！
============================================================
```

---

## 最佳实践

### ✅ 推荐的写法

1. **使用inplace操作**:
   ```python
   x = x.mul_(2.0)     # ✓ 保持dtype
   x = x.add_(1.0)
   x = x.clamp_(min=0.0)
   ```

2. **链式操作**:
   ```python
   result = (a + b).mul_(0.5)  # ✓ 先计算再乘
   ```

3. **使用tensor的方法而不是torch函数**:
   ```python
   x = x.clamp(min=1.0)          # ✓ 保持dtype
   x = torch.clamp(x, min=1.0)   # ❌ 可能提升dtype
   ```

4. **避免直接赋值浮点字面量**:
   ```python
   x[mask] = torch.zeros_like(x[mask])  # ✓
   x[mask] = 0.0                        # ❌ 可能变成float64
   ```

### ❌ 避免的写法

1. **浮点字面量在左侧**:
   ```python
   result = 0.5 * tensor    # ❌ dtype提升
   ```

2. **使用torch函数而不是方法**:
   ```python
   result = torch.clamp(x, min=1.0)  # ❌ 可能提升
   ```

3. **直接赋值浮点数**:
   ```python
   tensor[mask] = 1.0       # ❌ 可能提升
   ```

---

## 调试技巧

### 1. 快速检查dtype

```python
print(f"tensor.dtype: {tensor.dtype}")
```

### 2. 在可能出错的地方加断言

```python
assert tensor.dtype == torch.float32, f"Expected float32 but got {tensor.dtype}"
```

### 3. 使用autocast保护

```python
with torch.cuda.amp.autocast(dtype=torch.float32):
    result = model(x)
```

---

## 总结

- ✅ 修复了3处dtype提升问题
- ✅ 所有修复已验证通过测试
- ✅ 训练应该可以正常进行

**关键原则**:
1. 永远使用 tensor 的 inplace 方法 (`.mul_()`, `.add_()` 等)
2. 避免浮点字面量在运算符左侧
3. 使用 `tensor.method()` 而不是 `torch.function(tensor)`

**推荐**: 在训练前先运行 `python test_dtype_fix.py` 验证所有dtype正确。
