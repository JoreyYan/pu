# 多步扩散侧链生成：实验日志（2025-09-29）

> 本日志汇总今天全部讨论与实验：问题现象、诊断思路、关键实验、结果数据、证明点与结论，以及下一步行动清单。  
> 约定：t=0 为噪声端，t=1 为干净端；单步=1-step，欧拉=Euler，海恩=Heun。

---

## 0. 背景与现象

- 模型：主链刚体固定于本地系，侧链用网络预测；并带一个 21 类属性/氨基酸分类头（含 `other` 类，无 pad id）。  
- **异常**：  
  - **单步**（直接前向取 `x1_pred`）指标好：pLDDT≈64、PPL≈2、Recovery≈0.70。  
  - **多步**（欧拉/迭代）：**步数越多越差**。从第 2 步开始几何与分类同步退化（PPL 飙升、Recovery/结构崩）。  
- 初判：不是度量口径不一致导致（训练/验证/推理 CE 与 Acc 同口径掩码）；更像 **状态分布偏离训练桥（off-manifold / exposure bias）** 与 **向量场不收缩**。

---

## 1. 基线与对照结果

### 1.1 单步 vs 10 步（侧链）
| 指标（N=45） | 1-step | 10-step |
|---|---:|---:|
| TM-score | 0.603 ± 0.279 | 0.157 ± 0.035 |
| RMSD (Å) | 13.50 ± 14.87 | 24.96 ± 10.91 |
| pLDDT | 64.13 ± 19.18 | 32.30 ± 4.62 |
| pAE | 13.15 ± 6.36 | 23.93 ± 2.79 |
| Recovery | 0.695 ± 0.044 | 0.135 ± 0.033 |
| **Perplexity** | **2.03 ± 0.18** | **69.83 ± 14.07** |

> **证明**：多步推理显著恶化，尤其 PPL 从≈2 飙到≈70。

### 1.2 “只改 t，不改 x”（单步不同 t）
对同一类噪声输入（首步 x 相同），仅改变 `t_eval`：  
- t=min_t → PPL≈2.03，pLDDT≈64  
- t=0.3 → PPL≈2.20  
- t=0.7 → PPL≈4.05  
- t=1.0 → PPL≈5.47  

> **现象**：仅增大 t（坐标不变）即导致 PPL 上升、pLDDT 下降。  
> **初结**：分类头/特征通路对 t 的 **温度/校准敏感**，但不是主因（见 §1.3）。

### 1.3 固定桥上坐标，只扫 t
固定 `x_t = (1−0.5)·ε + 0.5·x_gt`（桥上 t=0.5 的样本），仅改变 `t_eval ∈ {min_t, 0.3, 0.5, 0.7, 1.0}`：  
- PPL 稳定在 1.6–1.9，pLDDT≈70，**不再随 t 爆炸**。

> **证明**：当 **x_t 在训练桥分布上** 时，t 本身不会引起 PPL 断崖。  
> **推论**：PPL 爆炸 **主要由 x_t 离桥** 引发，而非 t 条件本身。

---

## 2. “只改 x，不改 t”的关键诊断

### 2.1 第一步从 t₁→t₂ 的 “欧拉一步 vs 桥真值”
- **设置**：固定 `t₂`，对比两种输入下的单次 forward（同口径评测）  
  - **基线**：`x_t2_true = (1−t₂)·ε + t₂·x_gt`（桥分布样本）  
  - **一步外推**：从 `t₁=min_t` 用欧拉由 `x_t1` 推到 `x_t2_est`  
- **结果**（t₂=0.5）：  
  - 基线：pLDDT≈69.5，PPL≈1.59，TM≈0.638  
  - 一步外推：pLDDT≈39.2，PPL≈80.0，TM≈0.191

> **强证明**：**仅仅第一步外推**就把状态带离桥，导致 **第二次前向 OOD** → logits 校准崩溃、PPL 飙升、结构同步退化。  
> **结论**：**off-manifold 是主因**，不是评测口径问题。

---

## 3. 步内“向量场对齐”诊断（Δ 比较）

对 10 步，每步记录：  
- `Δ = x_{t2}^{Euler} − x_{t1}`（你的实际一步位移）  
- `Δ_true = x_{t2}^{true} − x_{t1}`（桥上“正确一步”）  
- 指标：`‖Δ‖, ‖Δ_true‖, relErr = ‖Δ‖/‖Δ_true‖, cos(Δ, Δ_true), 平行/法向分解`

**典型趋势**（从第 2 步起）：  
- `relErr` 上升到 0.6–0.85  
- `cos` 从 0.9 下降到 0.3 左右  
- `Δ⊥`（法向）与晚期 **平行方向超步** 同时放大

> **解释**：把 `x1_pred−x_t` 当速度方向，**方向逐步偏**（cos 下降），且后段 `α=Δt/(1−t)` 变大 → **平行超步 + 少量法向离桥累积**，导致 **几何与 PPL 同向恶化**。

---

## 4. 多种更新规则的尝试与结果

| 更新规则 | 结果概述 |
|---|---|
| **标准欧拉** `x_{t2}=x_t + ((x1_pred−x_t)/(1−t1))·Δt` | 从第 2 步起崩：PPL↑↑、Recovery/pLDDT↓↓ |
| **x0→x1_pred 线性插值** `x_{t2}=(1−t2)·x0 + t2·x1_pred` | 更差（PPL≈100+），说明“强锚定端点”不稳 |
| **“A1 自回授风格”**（用 `x1_pred` 作为下一步输入而不走欧拉） | 相比标准欧拉略缓解，但仍明显退化 |
| **logits t-钳制（只为 PPL 报告）** | 对抗“t 放大器”，但 **几何未变**，根因仍在离桥 |
| **Heun + α-cap + 位移限幅 + 早期桥混合**（多版本） | 修正“时间错配”后仍 **整体恶化**（虽略稳），证明 **积分器不是主因** |

> **总结**：**任何基于 `x1_pred` 当引导场的多步更新**，都无法从根上消除退化。问题在 **训练目标/向量场质量**，而非纯数值法。

---

## 5. 步内几何损失与 PPL 同步恶化

多步过程中打印：`atomsloss = mse + huber + pair` 与每步 Recovery/PPL。  
**统一现象**：`atomsloss` **单调上升**，Recovery↓、PPL↑。  
> **证明**：不仅是分类头校准崩，**几何本身也在变差**；与“向量场不收缩”一致。

---

## 6. 代码层面的关键核查与修正

- **时间方向**（t: 0→1）与 ODE 形式一致 ✅  
- **最初 α-cap 实现**存在 **时间–状态错配**：位移缩小但下一轮 t 仍跳网格 t₂ → 已修正为 `t_next = t1 + dt_eff`，Heun 的第二次评估也改到 `t_next` ✅  
- **Heun 真正生效**：二次前向使用 `(t_next, x_pred)` ✅  
- **桥混合**使用 `t_next` 与（若可得）`x1_pred@t_next` ✅  
- **位移限幅**建议 0.4–0.6 Å（当前 0.8 Å 略大）🟨  
- **side_exists 掩码**每步复用（保持无存在位为 0）🟨  
- **整体结论**：以上修正虽可止血一部分，但 **无法逆转根因** —— 训练目标把网络变成“端点回归器”，不具备稳定向量场的“收缩性”。

---

## 7. 核心结论（今天的“证明点”）

1. **根因**：当前网络更像 **端点回归器**，把 `x1_pred` 当场做多步积分 → **向量场不收缩**，状态迅速离桥，导致几何与分类同步崩。  
2. **证据链**：  
   - “只改 x”实验：一步外推即 OOD，PPL≈80；桥上基线 PPL≈1.6（§2.1）。  
   - 固定桥上 `x_t` 扫 `t`：PPL 稳定（≈1.6–1.9），排除 t 本身为主因（§1.3）。  
   - Δ 对齐诊断：`cos↓、relErr↑`，晚期 α 放大 → 方向偏 + 超步（§3）。  
   - 数值改良（Heun/α-cap/限幅/桥混合）仍失败（§4），证明 **不是积分器** 问题。  
   - 步内 `atomsloss` 单调升，几何本身变差（§5）。

---

## 8. 建议与可落地方案（按投入从低到高）

### A. 立即可用（不改训练）
- **默认采用 1-step 推理**（当前最稳、最优）。  
- 需要“迭代”时：改为 **固定小 t\*** 的 **定点迭代**  
  
\( x \gets (1-\lambda) x + \lambda\, x1\_{pred}(x, t^\*) \)
  
  \( t^* \in \{	ext{min}_t, 0.2\} \)，\( \lambda \in [0.1, 0.3] \)，迭代 5–10 次。  
  > 不沿时间轴推进，避免 \(1/(1-t)\) 放大器；通常不会“第 2 步起崩”。

### B. 轻量微调（强烈推荐）
1. **rollout-aware / pred-bridge 微调**  
   - 以 **模型滚出的 x_t**（或由 \(\hat x_1\) 构造的 pred-bridge）做训练输入，再训 CE 与坐标（可浅层回传）。  
   - 目的：让训练分布覆盖推理中会遇到的 **off-bridge** 区域，缓解曝光偏差。

2. **残差/速度目标**  
   - 让坐标头预测 \( r = x_1 - x_t \) 或 \( v = \frac{x_1 - x_t}{1 - t} \)（而不是 \( x_1 \) 本身），推理按 ODE 积分。  
   - 向量场天然“小修小补”，大幅提升多步稳定性。

3. **logits 口径**  
   - 训练与推理均只在 **桥上样本** 上监督/计算 CE；  
   - 报告时可加一次仅为 logits 的低 \( t_{eval} \) 前向以稳定 PPL（不改几何）。

### C. 结构性升级（中等投入）
- **Flow Matching / Conditional Flow Matching（v-prediction）**  
  - 直接训练 \( v_\theta(x_t,t) \approx \frac{x_1 - x_t}{1 - t} \)（或等价配方），并可叠加“一步重建 + LDDT”稳定细节；  
  - 采样用 Heun/EM + 后段细时刻/σ 调度。  
  - 与今日“根因”高度契合，可从根上恢复“扩散的意义”。

---

## 9. 开放问题与后续实验建议

- **（必要）回归 Δ 诊断曲线**：对任一新方案（定点迭代/微调/残差目标），记录每步 `cos / relErr / |Δ_true| / Δ⊥` 与 `atomsloss`，验证是否 **不再单调升**。  
- **噪声尺度匹配**：确认训练与推理使用的 ε 尺度一致（曾提 ±1 vs ±8 差异）。  
- **位移限幅/桥混合**：对前 3 步网格化搜索（ang_cap∈{0.4,0.6,0.8}Å，γ∈{0.85→0.6→0.4, 0.7→0.5→0.3}）。  
- **log-SNR 网格**：后半程细化，与 α-cap 叠加，观察晚期 |Δ_true| 与 PPL。  
- **自回授（feature-level）**：仅作为特征输入（不直接用于几何更新），检验对向量场“对 x_t 的敏感性”的改善。

---

## 10. 今日关键信息速览（TL;DR）

- **事实**：单步好；第 2 步起崩。  
- **已证**：崩坏源于 **x_t 离开训练桥**，不是 t 本身或积分器。  
- **原因**：把 **端点回归器** 当 **向量场** 用；向量场不收缩。  
- **对策**：  
  - 短期：用 1-step 或固定小 t 的定点迭代；  
  - 中期：rollout-aware 微调 + 残差/速度目标；  
  - 长期：切到 Flow Matching（v-prediction）框架。

