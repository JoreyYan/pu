# ESM Integration Guide for SideAtomsFlowModel

ESM (Evolutionary Scale Modeling) åºåˆ—ç‰¹å¾å·²æˆåŠŸé›†æˆåˆ° `SideAtomsFlowModel` ä¸­ï¼Œç”¨äº **backbone + atoms14 åŸå­æ‰©æ•£**ã€‚

## ğŸ“¦ å·²å®‰è£…çš„æ¨¡å—

1. **frozen_esm.py** - ESM ç¼–ç å™¨
   - ä½ç½®: `models/components/frozen_esm.py`
   - åŠŸèƒ½: æå– ESM single (residue-level) å’Œ pair (attention map) è¡¨ç¤º

2. **sequence_adapters.py** - åºåˆ—åˆ°ä¸»å¹²ç½‘ç»œçš„é€‚é…å™¨
   - ä½ç½®: `models/components/sequence_adapters.py`
   - åŠŸèƒ½: å°† ESM ç‰¹å¾æŠ•å½±åˆ°æ¨¡å‹ç»´åº¦å¹¶æ·»åŠ ä½ç½®ç¼–ç 

## ğŸ¯ SideAtomsFlowModel æ¶æ„

```
Input: noisy atoms14 (backbone + sidechain atoms)
    â†“
1. Extract sidechain atom features (SideAtomsFeatureHead)
    â†“
2. Extract structure features (BackboneEncoderGNN)
    â†“
3. [NEW] Extract sequence features (ESM)
   â”œâ”€ single: [B, L, nLayers, C_esm]
   â””â”€ pair (attention map): [B, L, L, nHeads*nLayers]
    â†“
4. Fuse all features:
   node_h = structure_features + esm_single
   edge_h = structure_edge_features + esm_pair
   combined = [node_features, sidechain_features, node_h]
    â†“
5. IPA Trunk + Transformer
    â†“
6. Predict atoms14 (backbone + sidechain)
```

## ğŸš€ å¦‚ä½•ä½¿ç”¨

### 1. é…ç½®æ–‡ä»¶è®¾ç½®

```yaml
model:
  use_esm: true                # å¯ç”¨ ESM
  esm_model: esm2_650M         # ESM æ¨¡å‹å¤§å°
  # å¯é€‰: esm2_8M_270K, esm2_35M_270K, esm2_650M, esm2_3B, esm2_15B

  ipa:
    c_s: 256                   # node feature dim
    c_z: 128                   # edge/pair feature dim (match ESM pair projection)

  edge_embed_size: 128         # must match c_z

  sidechain_atoms:
    A: 11                      # number of sidechain atoms
    hidden: 256                # sidechain feature dim
    conv_blocks: 4
    mlp_blocks: 4
```

### 2. æ•°æ®å‡†å¤‡

ç¡®ä¿ä½ çš„è¾“å…¥æ•°æ®åŒ…å«ä»¥ä¸‹å­—æ®µï¼š

```python
input_feats = {
    # å¿…éœ€å­—æ®µ
    'aatype': aatype,                    # [B, N] æ°¨åŸºé…¸ç±»å‹ (AlphaFold2 æ ¼å¼)
    'res_mask': res_mask,                # [B, N] æ®‹åŸº mask
    'diffuse_mask': diffuse_mask,        # [B, N] æ‰©æ•£ mask
    'res_idx': res_idx,                  # [B, N] æ®‹åŸºç´¢å¼•
    'chain_idx': chain_idx,              # [B, N] é“¾ç´¢å¼•

    # Noisy atoms
    'atoms14_local_t': atoms14_local_t,  # [B, N, 14, 3] noisy atoms14 (local frame)
    'atom14_gt_exists': atom14_exists,   # [B, N, 14] atomå­˜åœ¨æ€§
    'rotmats_1': rotmats_t,              # [B, N, 3, 3] noisy rotation
    'trans_1': trans_t,                  # [B, N, 3] noisy translation

    # Time step
    'r3_t': t,                           # float or [B, 1] æ—¶é—´æ­¥

    # å¯é€‰ï¼šself-conditioning
    'atoms14_local_sc': atoms14_local_sc, # [B, N, 14, 3] previous prediction
}
```

### 3. ä»£ç ä½¿ç”¨ç¤ºä¾‹

```python
from models.flow_model import SideAtomsFlowModel
from omegaconf import OmegaConf

# åŠ è½½é…ç½®
config = OmegaConf.load('your_config.yaml')

# åˆ›å»ºæ¨¡å‹ï¼ˆESM ä¼šè‡ªåŠ¨åˆå§‹åŒ–ï¼‰
model = SideAtomsFlowModel(config.model)

# Forward pass
output = model(input_feats)

# è¾“å‡º
side_atoms = output['side_atoms']              # [B, N, 11, 3] é¢„æµ‹çš„ä¾§é“¾åŸå­ (local)
atoms_global = output['atoms_global_full']     # [B, N, 14, 3] å…¨å±€åæ ‡
rigids = output['rigids_global']               # [B, N, 7] åˆšä½“å˜æ¢
logits = output['logits']                      # [B, N, 20] æ°¨åŸºé…¸ç±»å‹é¢„æµ‹ (å¯é€‰)
```

### 4. ä¸ä½¿ç”¨ ESM

å¦‚æœä¸æƒ³ä½¿ç”¨ ESMï¼š

```yaml
model:
  use_esm: false  # æˆ–è€…ä¸æ·»åŠ è¿™ä¸ªå­—æ®µ
```

æ¨¡å‹ä¼šè‡ªåŠ¨è·³è¿‡ ESM å¤„ç†ï¼Œä»…ä½¿ç”¨ç»“æ„å’Œä¾§é“¾ç‰¹å¾ã€‚

## ğŸ” ESM é›†æˆçš„å·¥ä½œæµç¨‹

### åœ¨ SideAtomsFlowModel.forward ä¸­ï¼š

```python
# 1. æå–ä¾§é“¾åŸå­ç‰¹å¾
sidechain_features = sidechain_head(atoms14_local_t[..., 3:14, :])
    â†“
# 2. æå–ç»“æ„ç‰¹å¾ (BackboneEncoderGNN)
node_h, edge_h = feature_graph(atoms14_local_for_graph)
    â†“
# 3. [NEW] æå–å¹¶èåˆ ESM ç‰¹å¾
if use_esm:
    seq_emb_s, seq_emb_z = seq_encoder(aatype, chain_idx, node_mask)
    seq_emb_s, seq_emb_z = sequence_to_trunk(seq_emb_s, seq_emb_z, ...)
    node_h = node_h + seq_emb_s  # èåˆ sequence åˆ° structure
    edge_h = edge_h + seq_emb_z  # èåˆ attention map åˆ° edge features
    â†“
# 4. ç»„åˆæ‰€æœ‰ç‰¹å¾
combined = [node_features, sidechain_features, node_h]
fused_node = feature_fusion(combined)
    â†“
# 5. IPA Trunk å¤„ç†
...
```

## ğŸ’¡ ä¸ºä»€ä¹ˆè¿™ä¸ªè®¾è®¡å¯¹ atoms14 æ‰©æ•£ç‰¹åˆ«å¥½ï¼Ÿ

### 1. **Sequence ä¿¡æ¯æŒ‡å¯¼ä¾§é“¾æ„è±¡**
- ESM çš„ single representation ç¼–ç äº†åºåˆ—åå¥½
- æŸäº›æ°¨åŸºé…¸ï¼ˆå¦‚ Pro, Glyï¼‰æœ‰ç‰¹å®šçš„æ„è±¡é™åˆ¶
- ESM å¸®åŠ©æ¨¡å‹å­¦ä¹ è¿™äº›åºåˆ—-æ„è±¡å…³ç³»

### 2. **Attention map æ•è·æ®‹åŸºé—´ç›¸äº’ä½œç”¨**
- ESM çš„ pair representation (attention map) ç¼–ç äº†å…±è¿›åŒ–ä¿¡æ¯
- å¯¹äºä¾§é“¾-ä¾§é“¾æ¥è§¦é¢„æµ‹å¾ˆæœ‰å¸®åŠ©
- ä¾‹å¦‚ï¼šç›æ¡¥ (Arg-Glu)ã€ç–æ°´ç›¸äº’ä½œç”¨ (Leu-Val-Ile)

### 3. **ä¸‰é‡ç‰¹å¾èåˆ**
```
Combined Features =
    â”œâ”€ Node features (time, mask, index)        â† æ‰©æ•£æ¡ä»¶
    â”œâ”€ Sidechain features (atoms geometry)      â† å±€éƒ¨å‡ ä½•
    â”œâ”€ Structure features (backbone GNN)        â† å…¨å±€ç»“æ„
    â””â”€ [NEW] ESM features (sequence context)    â† è¿›åŒ–ä¿¡æ¯
```

è¿™ç§è®¾è®¡å……åˆ†åˆ©ç”¨äº†ï¼š
- **ç»“æ„çº¦æŸ**ï¼ˆbackbone GNNï¼‰
- **å±€éƒ¨å‡ ä½•**ï¼ˆsidechain atomsï¼‰
- **åºåˆ—è¿›åŒ–**ï¼ˆESMï¼‰

## ğŸ“Š ç‰¹æ€§å¯¹æ¯”

| ç‰¹æ€§ | **æ—  ESM** | **æœ‰ ESM** |
|------|-----------|-----------|
| è¾“å…¥ä¿¡æ¯ | ç»“æ„ + ä¾§é“¾å‡ ä½• | ç»“æ„ + ä¾§é“¾å‡ ä½• + åºåˆ—è¿›åŒ– |
| Pair è¡¨ç¤º | ä»…ç»“æ„ pair | ç»“æ„ pair + ESM attention |
| ä¾§é“¾é¢„æµ‹ | åŸºäºå‡ ä½• | å‡ ä½• + åºåˆ—åå¥½ |
| è›‹ç™½è´¨è®¾è®¡ | ç»“æ„ä¼˜å…ˆ | ç»“æ„ + å¯è®¾è®¡æ€§ |
| è®­ç»ƒç¨³å®šæ€§ | ä¸­ç­‰ | æ›´å¥½ï¼ˆESM æ­£åˆ™åŒ–ï¼‰ |

## ğŸ§ª éªŒè¯ ESM æ˜¯å¦æ­£å¸¸å·¥ä½œ

```python
import torch
from models.flow_model import SideAtomsFlowModel

# åˆ›å»ºæ¨¡å‹
model = SideAtomsFlowModel(config.model)

# æ£€æŸ¥ ESM æ˜¯å¦å¯ç”¨
if model.use_esm:
    print("âœ“ ESM is enabled")
    print(f"  Model: {model.seq_encoder.esm}")
    print(f"  Single dim: {model.seq_encoder.single_dim}")
    print(f"  Num layers: {model.seq_encoder.num_layers}")
else:
    print("âœ— ESM is disabled")

# æµ‹è¯• forward pass
B, N = 2, 50
input_feats = {
    'aatype': torch.randint(0, 20, (B, N)),
    'res_mask': torch.ones(B, N),
    'diffuse_mask': torch.ones(B, N),
    'res_idx': torch.arange(N).unsqueeze(0).repeat(B, 1),
    'chain_idx': torch.ones(B, N, dtype=torch.long),
    'atoms14_local_t': torch.randn(B, N, 14, 3),
    'atom14_gt_exists': torch.ones(B, N, 14),
    'rotmats_1': torch.eye(3).unsqueeze(0).unsqueeze(0).repeat(B, N, 1, 1),
    'trans_1': torch.zeros(B, N, 3),
    'r3_t': torch.tensor([0.5]),
}

output = model(input_feats)
print("âœ“ Forward pass successful!")
print(f"  Side atoms shape: {output['side_atoms'].shape}")
print(f"  Global atoms shape: {output['atoms_global_full'].shape}")
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **aatype æ ¼å¼**ï¼šå¿…é¡»æ˜¯ AlphaFold2 æ ¼å¼ï¼ˆ0-20ï¼‰ï¼Œä¼šè‡ªåŠ¨è½¬æ¢ä¸º ESM æ ¼å¼
2. **å†…å­˜å ç”¨**ï¼šESM-650M éœ€è¦çº¦ 2.5GBï¼ŒESM-3B éœ€è¦çº¦ 6GB GPU å†…å­˜
3. **æ¨ç†é€Ÿåº¦**ï¼šESM forward å¢åŠ çº¦ 20-30% çš„æ¨ç†æ—¶é—´
4. **ESM å‚æ•°å†»ç»“**ï¼šESM å‚æ•°ä¸ä¼šåœ¨è®­ç»ƒä¸­æ›´æ–°ï¼Œåªè®­ç»ƒæŠ•å½±å±‚
5. **Batch size**ï¼šä½¿ç”¨ ESM æ—¶å¯èƒ½éœ€è¦å‡å° batch size

## ğŸ“ ä¸‹ä¸€æ­¥

1. åœ¨é…ç½®æ–‡ä»¶ä¸­å¯ç”¨ `use_esm: true`
2. å‡†å¤‡åŒ…å« `aatype` çš„è®­ç»ƒæ•°æ®
3. å¼€å§‹è®­ç»ƒ backbone + atoms14 æ‰©æ•£æ¨¡å‹
4. è§‚å¯Ÿ ESM æ˜¯å¦æå‡ä¾§é“¾æ„è±¡é¢„æµ‹è´¨é‡

## ğŸ¯ é¢„æœŸæ•ˆæœ

å¯ç”¨ ESM åï¼Œä½ åº”è¯¥çœ‹åˆ°ï¼š
- âœ… æ›´å‡†ç¡®çš„ä¾§é“¾æ–¹å‘ï¼ˆå°¤å…¶æ˜¯ aromatic æ®‹åŸºï¼‰
- âœ… æ›´åˆç†çš„ä¾§é“¾-ä¾§é“¾æ¥è§¦
- âœ… æ›´ç¨³å®šçš„è®­ç»ƒï¼ˆESM ä½œä¸ºæ­£åˆ™åŒ–ï¼‰
- âœ… æ›´å¥½çš„åºåˆ—-ç»“æ„ä¸€è‡´æ€§

Good luck with your backbone + atoms14 diffusion model! ğŸ‰
